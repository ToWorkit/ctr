{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hedy\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "训练GBDT\n",
    "'''\n",
    "\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegressionCV as LRCV\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import csc_matrix\n",
    "# 将模型整体实例化输出\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_train_file = \"F:/db/tmp/data/gbdt_test/output_train.txt\"\n",
    "output_feature_num_file = \"F:/db/tmp/data/gbdt_test/feature_num.txt\"\n",
    "output_model_file = \"F:/db/tmp/data/gbdt_test/gbdt.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到训练数据\n",
    "def get_train_data(train_file, feature_num_file):\n",
    "    '''\n",
    "    :param train_file:\n",
    "    :param feature_num_file:\n",
    "    :return:\n",
    "    '''\n",
    "    # 获取总的特征数目\n",
    "    # total_feature_num = GF.get_feature_num(feature_num_file)\n",
    "    total_feature_num = 103\n",
    "    \n",
    "    # label\n",
    "    train_label = np.genfromtxt(train_file, dtype = np.int32, delimiter = \",\", usecols = -1)\n",
    "    \n",
    "    # feature\n",
    "    feature_list = range(int(total_feature_num))\n",
    "    train_feature = np.genfromtxt(train_file, dtype = np.int32, delimiter = \",\", usecols = feature_list)\n",
    "    return train_feature, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbdt核心代码\n",
    "def train_tree_model_core(train_mat, tree_depth, tree_num, learning_rate):\n",
    "    '''\n",
    "    :param train_mat:\n",
    "        data AND label\n",
    "    :param tree_depth:\n",
    "        深度\n",
    "    :param tree_num:\n",
    "        树的个数\n",
    "    :param learning_rate:\n",
    "        步长\n",
    "    :return:\n",
    "        Booster结构的数据\n",
    "    ''' \n",
    "    \n",
    "    # 优化目标函数: 回归问题的线性优化 \"objective\": \"reg:linear\",\n",
    "    # 不输出的一些信息 \"silent\": 1\n",
    "    para_dict = {\"max_path\": tree_depth, \"eta\": learning_rate, \"objective\": \"reg:squarederror\", \"silent\": 1}\n",
    "    bst = xgb.train(para_dict, train_mat, tree_num)\n",
    "    \n",
    "    # 利用交叉验证（5折交叉验证）查看一些训练指标\n",
    "    # 每一棵树的 auc\n",
    "    print(xgb.cv(para_dict, train_mat, tree_num, nfold = 5, metrics = {\"auc\"}))\n",
    "    \n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择最优参数的参数列表\n",
    "def choose_parameter():\n",
    "    '''\n",
    "    :return:\n",
    "        list\n",
    "            [(tree_depth, tree_num, step_size) ...]\n",
    "    '''\n",
    "    result_list = []\n",
    "    tree_depth_list = [4, 5, 6]\n",
    "    tree_num_list = [10, 50, 100]\n",
    "    learning_rate_list = [0.3, 0.5, 0.7]\n",
    "    for ele_tree_depth in tree_depth_list:\n",
    "        for ele_tree_num in tree_num_list:\n",
    "            for ele_learning_rate in learning_rate_list:\n",
    "                result_list.append((ele_tree_depth, ele_tree_num, ele_learning_rate))\n",
    "\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为gbdt选取最优参数\n",
    "def grid_search(train_mat):\n",
    "    '''\n",
    "    :param train_mat:\n",
    "         data AND label\n",
    "    :return:\n",
    "    '''\n",
    "    # 构建参数列表\n",
    "    para_list = choose_parameter()\n",
    "\n",
    "    for ele in para_list:\n",
    "        (tree_depth, tree_num, learning_rate) = ele\n",
    "        para_dict = {\"max_path\": tree_depth, \"eta\": learning_rate, \"objective\": \"reg:squarederror\", \"silent\": 1}\n",
    "        res = xgb.cv(para_dict, train_mat, tree_num, nfold = 5, metrics = {\"auc\"})\n",
    "        print(res)\n",
    "        auc_score = res.loc[tree_num - 1, [\"test-auc-mean\"]].values[0]\n",
    "        \n",
    "        # GBDT\n",
    "        # 输出每一组参数以及auc的得分\n",
    "        # tree_depth: 6, tree_num: 50, learning_tare: 0.3, auc: 0.923335\n",
    "        # tree_depth: 5, tree_num: 50, learning_tare: 0.3, auc: 0.923335\n",
    "        # tree_depth: 4, tree_num: 50, learning_tare: 0.3, auc: 0.923335\n",
    "        print(\"tree_depth: %s, tree_num: %s, learning_tare: %s, auc: %f\" \\\n",
    "              % (tree_depth, tree_num, learning_rate, auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练gbdt\n",
    "def train_tree_model(train_file, feature_num_file, tree_model_file):\n",
    "    '''\n",
    "    :param train_file:\n",
    "        筛选好的训练数据\n",
    "    :param feature_num_file:\n",
    "        特征维度\n",
    "    :param tree_model_file\n",
    "        存储模型\n",
    "    '''\n",
    "\n",
    "    train_feature, train_label = get_train_data(train_file, feature_num_file)\n",
    "    \n",
    "    # 包装为xgboost需要的数据格式\n",
    "    train_mat = xgb.DMatrix(train_feature, train_label)\n",
    "    \n",
    "    # fm = fm - 1 + step_size * Tm\n",
    "    '''先手动设置参数，需要根据指标选择最优参数'''\n",
    "    # 树的个数\n",
    "    # tree_num = 50\n",
    "    tree_num = 10\n",
    "    # 树的深度\n",
    "    # tree_depth = 6\n",
    "    tree_depth = 4\n",
    "    # 步长\n",
    "    learning_rate = 0.3\n",
    "    # learning_rate = 0.3\n",
    "    \n",
    "    '''选择最优参数'''\n",
    "    # grid_search(train_mat)\n",
    "    bst = train_tree_model_core(train_mat, tree_depth, tree_num, learning_rate)\n",
    "    bst.save_model(tree_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "0        0.897219       0.002147       0.892260      0.001693\n",
      "1        0.905737       0.001149       0.900225      0.003617\n",
      "2        0.911490       0.000854       0.905588      0.003665\n",
      "3        0.915301       0.000697       0.908965      0.003656\n",
      "4        0.917767       0.001026       0.911052      0.003666\n",
      "5        0.920263       0.001220       0.912948      0.003493\n",
      "6        0.922710       0.001413       0.914579      0.003290\n",
      "7        0.924379       0.001134       0.915629      0.003058\n",
      "8        0.926490       0.000949       0.917177      0.003317\n",
      "9        0.928015       0.000914       0.917806      0.003342\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_tree_model(output_train_file, output_feature_num_file, output_model_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
