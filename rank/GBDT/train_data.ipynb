{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "树模型样本选择与特征选择\n",
    "GBDT不需要对连续特征作处理，只需要将离散特征向量化(01编码)即可\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"F:/db/tmp/data/lr/train.csv\"\n",
    "test_file = \"F:/db/tmp/data/lr/test.csv\"\n",
    "# 输出文件改为gbdt\n",
    "output_train_file = \"F:/db/tmp/data/gbdt_test/output_train.txt\"\n",
    "output_test_file = \"F:/db/tmp/data/gbdt_test/output_test.txt\"\n",
    "output_feature_num_file = \"F:/db/tmp/data/gbdt_test/feature_num.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(input_train_file, input_test_file):\n",
    "    '''\n",
    "    :param input_train_file:\n",
    "    :param input_test_file:\n",
    "    :return:\n",
    "        pd.DataFrame.train_data\n",
    "        pd.DataFrame.test_data\n",
    "    '''\n",
    "    # int类型单独声明，其他的都是string\n",
    "    dtype_dict = {\n",
    "        \"age\": np.int32,\n",
    "        \"education-num\": np.int32, # 受教育年限\n",
    "        \"capital-gain\": np.int32,\n",
    "        \"capital-loss\": np.int32,\n",
    "        \"hours-per-week\": np.int32\n",
    "    }\n",
    "    \n",
    "    # use_list = range(15)\n",
    "    use_list = list(range(0, 15))\n",
    "    # 去掉第三列\n",
    "    use_list.remove(2)\n",
    "    # 训练文件，分隔符，列索引，特征的数据类型，缺省值(默认值)，需要哪些特征\n",
    "    # na_values 无效\n",
    "    train_data_df = pd.read_csv(input_train_file, \n",
    "                                sep = \",\", \n",
    "                                header = 0, \n",
    "                                dtype = dtype_dict, \n",
    "                                na_values = [\"?\", \"NaN\", \"？\"], \n",
    "                                usecols = use_list)\n",
    "    \n",
    "    # print(train_data_df.shape) # (32561, 14)\n",
    "    # 样本选择，丢弃空值 NaN\n",
    "    # .replace(' ?', np.nan) 弥补 na_value 失效 bug\n",
    "    train_data_df = train_data_df.replace(' ?', np.nan).dropna(axis = 0, how = \"any\")\n",
    "    # print(train_data_df.shape) # (30162, 14)\n",
    "\n",
    "\n",
    "    # 测试集\n",
    "    test_data_df = pd.read_csv(input_test_file, sep = \",\", header = 0, dtype = dtype_dict, na_values= \"?\", usecols = use_list)\n",
    "    # print(test_data_df.shape) # (16281, 14)\n",
    "    test_data_df = test_data_df.replace(' ?', np.nan).dropna(axis = 0, how = \"any\")\n",
    "    # print(test_data_df.shape) # (15060, 14)\n",
    "\n",
    "    return train_data_df, test_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label处理\n",
    "def label_trans(x):\n",
    "    # print(x.strip())\n",
    "    '''\n",
    "    :param x:\n",
    "        label 值\n",
    "    :return:\n",
    "    '''\n",
    "    if x.strip() == \"<=50K\" or x.strip() == \"<=50K.\":\n",
    "        # print(x, \"<=50\")\n",
    "        return \"0\"\n",
    "    if x.strip() == \">50K\" or x.strip() == \">50K.\":\n",
    "        # print(x, \">50\")\n",
    "        return \"1\"\n",
    "    # print(type(x), x, \"0\")\n",
    "    return \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理label特征\n",
    "def process_label_feature(label_feature_str, df_in):\n",
    "    '''\n",
    "    :param label_feature_str:\n",
    "        label\n",
    "    :param df_in:\n",
    "        DataFrame\n",
    "    :return:\n",
    "    '''\n",
    "    # apply 对每一个元素执行自定义操作\n",
    "    df_in.loc[:, label_feature_str] = df_in.loc[:, label_feature_str].apply(label_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排序并记录位置\n",
    "def dict_trans(dict_in):\n",
    "    '''\n",
    "    :param dict_in:\n",
    "        key: str\n",
    "        value int\n",
    "    :return:\n",
    "        dict\n",
    "            key: str\n",
    "            value: key所对应的位置\n",
    "    '''\n",
    "    output_dict = {}\n",
    "    index = 0\n",
    "    for zuhe in sorted(dict_in.items(), key = operator.itemgetter(1), reverse = True):\n",
    "        output_dict[zuhe[0]] = index\n",
    "        index += 1\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_to_feature(x, feature_dict):\n",
    "    '''\n",
    "    离散特征\n",
    "    :param x:\n",
    "    :param feature_dict:\n",
    "    :return:\n",
    "        str\n",
    "          1, 0, 0\n",
    "    '''\n",
    "    # 有多少key就是多少维度\n",
    "    output_list = [0] * len(feature_dict)\n",
    "    if x not in feature_dict:\n",
    "        # 全部为 0\n",
    "        return \",\".join([str(ele) for ele in output_list])\n",
    "    else:\n",
    "        index = feature_dict[x]\n",
    "        output_list[index] = 1\n",
    "        \n",
    "    return \",\".join([str(ele) for ele in output_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理离散特征\n",
    "def process_dis_feature(feature_str, df_train, df_test):\n",
    "    '''\n",
    "    先统计该特征一共有哪些值，作离散化 onehot\n",
    "    保持训练集和测试集一致\n",
    "    '''\n",
    "    # 统计\n",
    "    origin_dict = df_train.loc[:, feature_str].value_counts().to_dict()\n",
    "    \n",
    "    # 类别下的分类: 值\n",
    "    # print(origin_dict)\n",
    "    feature_dict = dict_trans(origin_dict)\n",
    "    df_train.loc[:, feature_str] = df_train.loc[:, feature_str].apply(dis_to_feature, args = (feature_dict, ))\n",
    "    df_test.loc[:, feature_str] = df_test.loc[:, feature_str].apply(dis_to_feature, args = (feature_dict, ))\n",
    "    \n",
    "    # onehot\n",
    "    # print(df_train.loc[:3, feature_str])\n",
    "    # 原始位置\n",
    "    # print(feature_dict)\n",
    "    # 每一个特征离散化后的维度\n",
    "    return len(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将dataframe的数据写入文件当中\n",
    "def output_file(df_in, out_file):\n",
    "    # 按行写入\n",
    "    fw = open(out_file, \"w+\", encoding = \"utf-8\")\n",
    "    for row_index in df_in.index:\n",
    "        outline = \",\".join([str(ele) for ele in df_in.loc[row_index].values])\n",
    "        fw.write(outline + \"\\n\")\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ana_train_data(input_train_data, input_test_data, out_train_file, out_test_file, feature_num_file):\n",
    "    '''\n",
    "    需要对训练集和测试集做同样的数据处理\n",
    "    :param input_file_data:\n",
    "    :param input_test_data:\n",
    "    :param out_train_data:\n",
    "    :param out_test_file:\n",
    "    :param feature_num_file:\n",
    "        特征数目输出文件\n",
    "    :return:\n",
    "    '''\n",
    "    # 读入文件\n",
    "    train_data_df, test_data_df = get_input(input_train_data, input_test_data)\n",
    "    label_feature_str = \"label\"\n",
    "    # 需要处理的离散特征\n",
    "    dis_feature_list = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\"]\n",
    "    # 连续特征\n",
    "    con_feature_list = [\"age\", \"education-num\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]\n",
    "\n",
    "    process_label_feature(label_feature_str, train_data_df)\n",
    "    process_label_feature(label_feature_str, test_data_df)\n",
    "\n",
    "    # 统计离散化成了多少维\n",
    "    dis_feature_num = 0\n",
    "    # 统计连续特征离散化成了多少维\n",
    "    con_feature_num = 0\n",
    "\n",
    "\n",
    "    # 对每一个特征都做相应的处理\n",
    "    # 离散特征\n",
    "    for dis_feature in dis_feature_list:\n",
    "        # 每个特征的维度\n",
    "        tmp_feature_num = process_dis_feature(dis_feature, train_data_df, test_data_df)\n",
    "        dis_feature_num += tmp_feature_num\n",
    "\n",
    "    # 不处理连续特征\n",
    "    for con_feature in con_feature_list:\n",
    "        # 每个特征的维度 为 1\n",
    "        con_feature_num += 1\n",
    "    print(train_data_df.shape)\n",
    "    print(test_data_df.shape)\n",
    "\n",
    "    # 写入训练文件\n",
    "    output_file(train_data_df, out_train_file)\n",
    "    # 测试\n",
    "    output_file(test_data_df, out_test_file)\n",
    "\n",
    "\n",
    "    # 特征数目(离散特征 + 连续特征)输出文件, 这样后面的训练模型和预测就可以从这里去特征数目了，且特征数目发生变化也不会受影响\n",
    "    fw = open(feature_num_file, \"w+\")\n",
    "    fw.write(\"feature_num=\" + str(dis_feature_num + con_feature_num))\n",
    "    fw.close()\n",
    "\n",
    "    # 离散特征和连续特征以及特征组合的维度\n",
    "    print(dis_feature_num)\n",
    "    print(con_feature_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 14)\n",
      "(15060, 14)\n",
      "98\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ana_train_data(train_file, test_file, output_train_file, output_test_file, output_feature_num_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
