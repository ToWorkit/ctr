{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from process.ipynb\n"
     ]
    }
   ],
   "source": [
    "import Ipynb_importer\n",
    "import process\n",
    "import numpy as np\n",
    "import jieba\n",
    "import gensim\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSACorpus():\n",
    "    \"\"\"将文档转为gensim中的LSA可以读取和处理的格式\"\"\"\n",
    "    def __init__(self, stopWordsPath, fileTitle, fileIntro):\n",
    "        initData=process.Init()\n",
    "        self.stopWords=initData.loadStopWords(stopWordsPath)\n",
    "        self.filmTitles,self.filmDocs=initData.readData(fileTitle,fileIntro)\n",
    "        # ictionary中的参数为被拆成单词集合的文档的集合,dictionary把所有单词取一个set(),并对set中每个单词分配一个Id号的map\n",
    "        # 所有文本的单词拿出来构成一个字典，将文档转换为LSA可以处理的格式\n",
    "        self.dictionary=gensim.corpora.Dictionary(self.iter_docs())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filmDocs)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for tokens in self.iter_docs():\n",
    "            # doc2bow根据本词典构构造的向量,是把文档 doc变成一个稀疏向量，[(0, 1), (1, 1)]，表明id为0,1的词汇出现了1次，至于其他词汇，没有出现。\n",
    "            yield self.dictionary.doc2bow(tokens)\n",
    "        \n",
    "    def iter_docs(self):\n",
    "        for filmDoc in self.filmDocs:\n",
    "            yield(word for word in jieba.cut(filmDoc) if word not in self.stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "利用潜在语义分析计算查询与文档的相关度\n",
    "首先将文档语料映射成三个矩阵U*S*V，这三个矩阵分别是词与主题矩阵，代表词与主题的相关度；主题的对角矩阵；主题与文档矩阵，\n",
    "表示主题在文档中的分布\n",
    "然后将查询词也映射到空间中qt=q*U*S中，再qt*V得到查询与每个文档的相关度，返回前top-k个文档\n",
    "这个方法不同于传统的基于词存在的相关计算，它可以计算出词的相近词，就是説可以计算词不在文档中的相关度\n",
    "'''\n",
    "class LSA():\n",
    "    def __init__(self,stopWordsPath, fileTitle, fileIntro):\n",
    "        # 将文档转为gensim中的LSA可以读取和处理的格式\n",
    "        self.corpus = LSACorpus(stopWordsPath, fileTitle, fileIntro)\n",
    "        \n",
    "    def lsaSearch(self,query):\n",
    "        dict_copus = self.corpus.dictionary\n",
    "        # 指定10个主题\n",
    "        topics = 10\n",
    "        lsi = models.LsiModel(self.corpus, num_topics=topics, id2word=dict_copus)\n",
    "        # 获取U、V、S矩阵，查询词转换到潜在空间需要这些分解的矩阵\n",
    "        U = lsi.projection.u\n",
    "        S = np.eye(topics) * lsi.projection.s\n",
    "        V = gensim.matutils.corpus2dense(lsi[self.corpus], len(lsi.projection.s)).T / lsi.projection.s\n",
    "        \n",
    "        # 单词的索引字典，将查询词转换为它在dict_copus相应的索引词\n",
    "        dict_words = {}\n",
    "        for i in range(len(dict_copus)):\n",
    "            dict_words[dict_copus[i]] = i\n",
    "            \n",
    "        # 将查询query转换为查询词向量\n",
    "        q=np.zeros(len(dict_words.keys()))\n",
    "        for word in jieba.cut(query):\n",
    "            q[dict_words[word]]=1\n",
    "            \n",
    "        #将query的q权重向量（它经分词后的单词在dict_words中的相应索词）\n",
    "        # 映射到qt中 qt=q*U*S为查询的词矩阵（就是查询中的词与主题矩阵，与主题的相关度）,大小与字典库相同\n",
    "        qt=np.dot(np.dot(q,U),S)\n",
    "        \n",
    "        # 与电影中的每篇简介的相关度\n",
    "        similarity=np.zeros(len(self.corpus.filmDocs))\n",
    "        \n",
    "        # 这里的V应该行是文档，列是主题（代表该文档在各个主题上的相关度），便与查询词矩阵点乘得到查询与文档的相关度\n",
    "        for index in range(len(V)):\n",
    "            similarity[index]=np.dot(qt,V[index])\n",
    "            \n",
    "        index_sim=np.argsort(similarity)[::-1] # 排序\n",
    "        \n",
    "        for index in list(index_sim)[:5]:#最相关的前5个文档\n",
    "            print('sim: %f,title: %s' % (similarity[index], self.corpus.filmTitles[index]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
