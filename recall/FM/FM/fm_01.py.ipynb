{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试，数值型特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "import numpy as np\n",
    "from random import normalvariate  # 正态分布\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = 'C:/Users/hedy/Downloads/fm/diabetes_train.txt'   #请换为自己文件的路径\n",
    "testData = 'C:/Users/hedy/Downloads/fm/diabetes_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData(data):\n",
    "    \"\"\"预处理\"\"\"\n",
    "    # 获取特征\n",
    "    feature = np.array(data.iloc[:, :-1])\n",
    "    # 将标签转为 1 和 -1\n",
    "    label = data.iloc[:, -1].map(lambda x: 1 if x == 1 else -1)\n",
    "    \n",
    "    # 将数组按行进行归一化（最大最小值归一化）\n",
    "    zmax, zmin = feature.max(axis=0), feature.min(axis=0)\n",
    "    feature = (feature - zmin) / (zmax - zmin)\n",
    "    \n",
    "    label = np.array(label)\n",
    "    \n",
    "    return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(inx):\n",
    "    #return 1. / (1. + exp(-max(min(inx, 15.), -15.)))\n",
    "    return 1.0 / (1 + exp(-inx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function numpy.shape>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_FM(dataMatrix, classLabels, k, iter):\n",
    "    '''\n",
    "    :param dataMatrix:  特征矩阵 mat\n",
    "    :param classLabels: 类别矩阵 列表\n",
    "    :param k:           辅助向量的大小\n",
    "    :param iter:        迭代次数\n",
    "    :return:\n",
    "    '''\n",
    "    m, n = np.shape(dataMatrix)   #矩阵的行列数，即样本数和特征数\n",
    "    \n",
    "    alpha = 0.01\n",
    "    # 初始化参数\n",
    "    # w = random.randn(n, 1)#其中n是特征的个数\n",
    "    w = np.zeros((n, 1))      #一阶特征的系数\n",
    "    w_0 = 0.\n",
    "    v = normalvariate(0, 0.2) * np.ones((n, k))   #即生成辅助向量，用来训练二阶交叉特征的系数\n",
    "    \n",
    "    for it in range(iter):\n",
    "        for x in range(m):  # 随机优化，每次只使用一个样本\n",
    "            # 二阶项的计算\n",
    "            inter_1 = dataMatrix[x] * v\n",
    "            inter_2 = np.multiply(dataMatrix[x], dataMatrix[x]) * np.multiply(v, v)  #二阶交叉项的计算\n",
    "            interaction = sum(np.multiply(inter_1, inter_1) - inter_2) / 2.       #二阶交叉项计算完成\n",
    "            \n",
    "            p = w_0 + dataMatrix[x] * w + interaction  # 计算预测的输出，即FM的全部项之和\n",
    "            loss = 1-sigmoid(classLabels[x] * p[0, 0])    #计算损失\n",
    "            \n",
    "            w_0 = w_0 + alpha * loss * classLabels[x]\n",
    "            \n",
    "            for i in range(n):\n",
    "                if dataMatrix[x, i] != 0:\n",
    "                    w[i, 0] = w[i, 0] + alpha * loss * classLabels[x] * dataMatrix[x, i]\n",
    "                    for j in range(k):\n",
    "                        v[i, j] = v[i, j] + alpha * loss * classLabels[x] * (dataMatrix[x, i] * inter_1[0, j] - v[i, j] * dataMatrix[x, i] * dataMatrix[x, i])\n",
    "        print(\"第{}次迭代后的损失为{}\".format(it, loss))\n",
    "        \n",
    "    return w_0, w, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(dataMatrix, classLabels, w_0, w, v):\n",
    "    m, n = np.shape(dataMatrix)\n",
    "    allItem = 0\n",
    "    error = 0\n",
    "    result = []\n",
    "    for x in range(m):   #计算每一个样本的误差\n",
    "        allItem += 1\n",
    "        inter_1 = dataMatrix[x] * v\n",
    "        inter_2 = np.multiply(dataMatrix[x], dataMatrix[x]) * np.multiply(v, v)\n",
    "        interaction = sum(np.multiply(inter_1, inter_1) - inter_2) / 2.\n",
    "        p = w_0 + dataMatrix[x] * w + interaction  # 计算预测的输出\n",
    "        \n",
    "        pre = sigmoid(p[0, 0])\n",
    "        result.append(pre)\n",
    "        \n",
    "        if pre < 0.5 and classLabels[x] == 1.0:\n",
    "            error += 1\n",
    "        elif pre >= 0.5 and classLabels[x] == -1.0:\n",
    "            error += 1\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return float(error) / allItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练\n",
      "第0次迭代后的损失为0.38879551291228154\n",
      "第1次迭代后的损失为0.39841261970832487\n",
      "第2次迭代后的损失为0.4173696802918623\n",
      "第3次迭代后的损失为0.4353136138477911\n",
      "第4次迭代后的损失为0.4510093170084324\n",
      "第5次迭代后的损失为0.46421451900845767\n",
      "第6次迭代后的损失为0.475040706528265\n",
      "第7次迭代后的损失为0.48373985996401114\n",
      "第8次迭代后的损失为0.49060134623983254\n",
      "第9次迭代后的损失为0.49590520873762156\n",
      "第10次迭代后的损失为0.49990262529883056\n",
      "第11次迭代后的损失为0.5028098033052779\n",
      "第12次迭代后的损失为0.5048085960161126\n",
      "第13次迭代后的损失为0.5060501977687205\n",
      "第14次迭代后的损失为0.5066598785210406\n",
      "第15次迭代后的损失为0.5067416699847744\n",
      "第16次迭代后的损失为0.5063824943110815\n",
      "第17次迭代后的损失为0.5056555648446419\n",
      "第18次迭代后的损失为0.5046230713027383\n",
      "第19次迭代后的损失为0.5033382469100804\n",
      "第20次迭代后的损失为0.5018469421865372\n",
      "第21次迭代后的损失为0.5001888256784427\n",
      "第22次迭代后的损失为0.49839831293674475\n",
      "第23次迭代后的损失为0.49650530178175345\n",
      "第24次迭代后的损失为0.4945357700175428\n",
      "第25次迭代后的损失为0.4925122738430131\n",
      "第26次迭代后的损失为0.49045437191325936\n",
      "第27次迭代后的损失为0.4883789909431734\n",
      "第28次迭代后的损失为0.48630074305888027\n",
      "第29次迭代后的损失为0.4842322018367402\n",
      "第30次迭代后的损失为0.4821841422706584\n",
      "第31次迭代后的损失为0.48016574910945287\n",
      "第32次迭代后的损失为0.4781847976404363\n",
      "第33次迭代后的损失为0.4762478107726613\n",
      "第34次迭代后的损失为0.47436019603872015\n",
      "第35次迭代后的损失为0.4725263658266816\n",
      "第36次迭代后的损失为0.4707498437698684\n",
      "第37次迭代后的损失为0.46903335978717364\n",
      "第38次迭代后的损失为0.4673789358158439\n",
      "第39次迭代后的损失为0.46578796384529364\n",
      "第40次迭代后的损失为0.4642612774702417\n",
      "第41次迭代后的损失为0.4627992178500032\n",
      "第42次迭代后的损失为0.46140169469482195\n",
      "第43次迭代后的损失为0.4600682426989312\n",
      "第44次迭代后的损失为0.4587980736977597\n",
      "第45次迭代后的损失为0.45759012473453886\n",
      "第46次迭代后的损失为0.45644310216934936\n",
      "第47次迭代后的损失为0.45535552194134477\n",
      "第48次迭代后的损失为0.4543257460934347\n",
      "第49次迭代后的损失为0.45335201568029526\n",
      "第50次迭代后的损失为0.45243248019898274\n",
      "第51次迭代后的损失为0.45156522370212626\n",
      "第52次迭代后的损失为0.45074828777327824\n",
      "第53次迭代后的损失为0.44997969156049367\n",
      "第54次迭代后的损失为0.4492574490764606\n",
      "第55次迭代后的损失为0.44857958398097053\n",
      "第56次迭代后的损失为0.4479441420643565\n",
      "第57次迭代后的损失为0.44734920164909453\n",
      "第58次迭代后的损失为0.4467928821216217\n",
      "第59次迭代后的损失为0.44627335079824404\n",
      "第60次迭代后的损失为0.44578882831852484\n",
      "第61次迭代后的损失为0.4453375927473848\n",
      "第62次迭代后的损失为0.44491798255385373\n",
      "第63次迭代后的损失为0.44452839862063465\n",
      "第64次迭代后的损失为0.444167305424637\n",
      "第65次迭代后的损失为0.4438332315148966\n",
      "第66次迭代后的损失为0.44352476940094454\n",
      "第67次迭代后的损失为0.44324057495211977\n",
      "第68次迭代后的损失为0.4429793663963554\n",
      "第69次迭代后的损失为0.4427399229960476\n",
      "第70次迭代后的损失为0.4425210834685015\n",
      "第71次迭代后的损失为0.4423217442092896\n",
      "第72次迭代后的损失为0.4421408573685839\n",
      "第73次迭代后的损失为0.4419774288231596\n",
      "第74次迭代后的损失为0.4418305160801822\n",
      "第75次迭代后的损失为0.4416992261430729\n",
      "第76次迭代后的损失为0.4415827133646987\n",
      "第77次迭代后的损失为0.4414801773086674\n",
      "第78次迭代后的损失为0.44139086063563293\n",
      "第79次迭代后的损失为0.4413140470282332\n",
      "第80次迭代后的损失为0.44124905916539003\n",
      "第81次迭代后的损失为0.4411952567542733\n",
      "第82次迭代后的损失为0.4411520346261696\n",
      "第83次迭代后的损失为0.44111882090071663\n",
      "第84次迭代后的损失为0.44109507522155555\n",
      "第85次迭代后的损失为0.44108028706517144\n",
      "第86次迭代后的损失为0.4410739741237242\n",
      "第87次迭代后的损失为0.44107568076184134\n",
      "第88次迭代后的损失为0.4410849765466702\n",
      "第89次迭代后的损失为0.441101454849948\n",
      "第90次迭代后的损失为0.4411247315204546\n",
      "第91次迭代后的损失为0.44115444362485523\n",
      "第92次迭代后的损失为0.4411902482547174\n",
      "第93次迭代后的损失为0.4412318213973274\n",
      "第94次迭代后的损失为0.44127885686776636\n",
      "第95次迭代后的损失为0.44133106529968946\n",
      "第96次迭代后的损失为0.4413881731921835\n",
      "第97次迭代后的损失为0.4414499220100887\n",
      "第98次迭代后的损失为0.4415160673351992\n",
      "第99次迭代后的损失为0.4415863780657755\n",
      "第100次迭代后的损失为0.44166063566191105\n",
      "第101次迭代后的损失为0.4417386334343021\n",
      "第102次迭代后的损失为0.4418201758741087\n",
      "第103次迭代后的损失为0.441905078021646\n",
      "第104次迭代后的损失为0.4419931648717328\n",
      "第105次迭代后的损失为0.4420842708136602\n",
      "第106次迭代后的损失为0.4421782391037795\n",
      "第107次迭代后的损失为0.4422749213688385\n",
      "第108次迭代后的损失为0.4423741771382993\n",
      "第109次迭代后的损失为0.4424758734039057\n",
      "第110次迭代后的损失为0.4425798842049393\n",
      "第111次迭代后的损失为0.4426860902376152\n",
      "第112次迭代后的损失为0.4427943784871915\n",
      "第113次迭代后的损失为0.44290464188145984\n",
      "第114次迭代后的损失为0.4430167789643006\n",
      "第115次迭代后的损失为0.4431306935881415\n",
      "第116次迭代后的损失为0.44324629462416354\n",
      "第117次迭代后的损失为0.443363495689194\n",
      "第118次迭代后的损失为0.44348221488829376\n",
      "第119次迭代后的损失为0.4436023745720804\n",
      "第120次迭代后的损失为0.4437239011079249\n",
      "第121次迭代后的损失为0.44384672466417174\n",
      "第122次迭代后的损失为0.4439707790066081\n",
      "第123次迭代后的损失为0.44409600130645477\n",
      "第124次迭代后的损失为0.44422233195919636\n",
      "第125次迭代后的损失为0.4443497144135756\n",
      "第126次迭代后的损失为0.4444780950101904\n",
      "第127次迭代后的损失为0.44460742282908683\n",
      "第128次迭代后的损失为0.44473764954584516\n",
      "第129次迭代后的损失为0.44486872929563437\n",
      "第130次迭代后的损失为0.4450006185447781\n",
      "第131次迭代后的损失为0.44513327596939767\n",
      "第132次迭代后的损失为0.44526666234070733\n",
      "第133次迭代后的损失为0.4454007404165712\n",
      "第134次迭代后的损失为0.4455354748389784\n",
      "第135次迭代后的损失为0.4456708320370768\n",
      "第136次迭代后的损失为0.44580678013544217\n",
      "第137次迭代后的损失为0.44594328886730283\n",
      "第138次迭代后的损失为0.4460803294924104\n",
      "第139次迭代后的损失为0.4462178747193135\n",
      "第140次迭代后的损失为0.44635589863177016\n",
      "第141次迭代后的损失为0.4464943766190781\n",
      "第142次迭代后的损失为0.4466332853100785\n",
      "第143次迭代后的损失为0.4467726025106643\n",
      "第144次迭代后的损失为0.44691230714455477\n",
      "第145次迭代后的损失为0.4470523791971913\n",
      "第146次迭代后的损失为0.4471927996625604\n",
      "第147次迭代后的损失为0.44733355049277823\n",
      "第148次迭代后的损失为0.44747461455031157\n",
      "第149次迭代后的损失为0.44761597556265775\n",
      "第150次迭代后的损失为0.447757618079368\n",
      "第151次迭代后的损失为0.4478995274312919\n",
      "第152次迭代后的损失为0.44804168969189995\n",
      "第153次迭代后的损失为0.44818409164059547\n",
      "第154次迭代后的损失为0.44832672072790003\n",
      "第155次迭代后的损失为0.4484695650424019\n",
      "第156次迭代后的损失为0.4486126132793907\n",
      "第157次迭代后的损失为0.4487558547110806\n",
      "第158次迭代后的损失为0.44889927915833416\n",
      "第159次迭代后的损失为0.4490428769638166\n",
      "第160次迭代后的损失为0.44918663896648825\n",
      "第161次迭代后的损失为0.4493305564773906\n",
      "第162次迭代后的损失为0.44947462125663684\n",
      "第163次迭代后的损失为0.4496188254915525\n",
      "第164次迭代后的损失为0.44976316177590303\n",
      "第165次迭代后的损失为0.4499076230901604\n",
      "第166次迭代后的损失为0.45005220278274394\n",
      "第167次迭代后的损失为0.4501968945521889\n",
      "第168次迭代后的损失为0.4503416924302055\n",
      "第169次迭代后的损失为0.4504865907655643\n",
      "第170次迭代后的损失为0.450631584208774\n",
      "第171次迭代后的损失为0.45077666769753577\n",
      "第172次迭代后的损失为0.45092183644286643\n",
      "第173次迭代后的损失为0.45106708591595357\n",
      "第174次迭代后的损失为0.4512124118356158\n",
      "第175次迭代后的损失为0.451357810156393\n",
      "第176次迭代后的损失为0.45150327705721516\n",
      "第177次迭代后的损失为0.4516488089306223\n",
      "第178次迭代后的损失为0.451794402372502\n",
      "第179次迭代后的损失为0.4519400541723452\n",
      "第180次迭代后的损失为0.4520857613039504\n",
      "第181次迭代后的损失为0.4522315209165956\n",
      "第182次迭代后的损失为0.45237733032663163\n",
      "第183次迭代后的损失为0.4525231870094836\n",
      "第184次迭代后的损失为0.45266908859203736\n",
      "第185次迭代后的损失为0.4528150328453898\n",
      "第186次迭代后的损失为0.45296101767796226\n",
      "第187次迭代后的损失为0.45310704112892886\n",
      "第188次迭代后的损失为0.45325310136197117\n",
      "第189次迭代后的损失为0.45339919665933126\n",
      "第190次迭代后的损失为0.4535453254161508\n",
      "第191次迭代后的损失为0.45369148613507715\n",
      "第192次迭代后的损失为0.453837677421138\n",
      "第193次迭代后的损失为0.45398389797685545\n",
      "第194次迭代后的损失为0.4541301465975892\n",
      "第195次迭代后的损失为0.45427642216711817\n",
      "第196次迭代后的损失为0.4544227236534131\n",
      "第197次迭代后的损失为0.4545690501046349\n",
      "第198次迭代后的损失为0.45471540064529936\n",
      "第199次迭代后的损失为0.454861774472648\n",
      "训练准确性为：0.753507\n",
      "训练用时为：0:01:41.566000\n",
      "开始测试\n",
      "测试准确性为：0.812734\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train = pd.read_csv(trainData)\n",
    "    test = pd.read_csv(testData)\n",
    "    dataTrain, labelTrain = preprocessData(train)\n",
    "    dataTest, labelTest = preprocessData(test)\n",
    "    date_startTrain = datetime.now()\n",
    "    \n",
    "    print    (\"开始训练\")\n",
    "    \n",
    "    w_0, w, v = SGD_FM(np.mat(dataTrain), labelTrain, 20, 200)\n",
    "    print(\"训练准确性为：%f\" % (1 - getAccuracy(np.mat(dataTrain), labelTrain, w_0, w, v)))\n",
    "    \n",
    "    date_endTrain = datetime.now()\n",
    "    print(\"训练用时为：%s\" % (date_endTrain - date_startTrain))\n",
    "    \n",
    "    print(\"开始测试\")\n",
    "    print(\"测试准确性为：%f\" % (1 - getAccuracy(np.mat(dataTest), labelTest, w_0, w, v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
