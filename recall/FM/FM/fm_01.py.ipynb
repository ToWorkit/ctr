{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试，数值型特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "import numpy as np\n",
    "from random import normalvariate  # 正态分布\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = 'C:/Users/hedy/Downloads/fm/diabetes_train.txt'   #请换为自己文件的路径\n",
    "testData = 'C:/Users/hedy/Downloads/fm/diabetes_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData(data):\n",
    "    \"\"\"预处理\"\"\"\n",
    "    # 获取特征\n",
    "    feature = np.array(data.iloc[:, :-1])\n",
    "    # 将标签转为 1 和 -1\n",
    "    label = data.iloc[:, -1].map(lambda x: 1 if x == 1 else -1)\n",
    "    \n",
    "    # 将数组按行进行归一化（最大最小值归一化）\n",
    "    zmax, zmin = feature.max(axis=0), feature.min(axis=0)\n",
    "    feature = (feature - zmin) / (zmax - zmin)\n",
    "    \n",
    "    label = np.array(label)\n",
    "    \n",
    "    return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(inx):\n",
    "    #return 1. / (1. + exp(-max(min(inx, 15.), -15.)))\n",
    "    return 1.0 / (1 + exp(-inx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function numpy.shape>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_FM(dataMatrix, classLabels, k, iter):\n",
    "    '''\n",
    "    :param dataMatrix:  特征矩阵 mat\n",
    "    :param classLabels: 类别矩阵 列表\n",
    "    :param k:           辅助向量的大小\n",
    "    :param iter:        迭代次数\n",
    "    :return:\n",
    "    '''\n",
    "    m, n = np.shape(dataMatrix)   #矩阵的行列数，即样本数和特征数\n",
    "    \n",
    "    alpha = 0.01\n",
    "    # 初始化参数\n",
    "    # w = random.randn(n, 1)#其中n是特征的个数\n",
    "    w = np.zeros((n, 1))      #一阶特征的系数\n",
    "    w_0 = 0.\n",
    "    v = normalvariate(0, 0.2) * np.ones((n, k))   #即生成辅助向量，用来训练二阶交叉特征的系数\n",
    "    \n",
    "    for it in range(iter):\n",
    "        for x in range(m):  # 随机优化，每次只使用一个样本\n",
    "            # 二阶项的计算\n",
    "            inter_1 = dataMatrix[x] * v\n",
    "            inter_2 = np.multiply(dataMatrix[x], dataMatrix[x]) * np.multiply(v, v)  #二阶交叉项的计算\n",
    "            interaction = sum(np.multiply(inter_1, inter_1) - inter_2) / 2.       #二阶交叉项计算完成\n",
    "            \n",
    "            p = w_0 + dataMatrix[x] * w + interaction  # 计算预测的输出，即FM的全部项之和\n",
    "            loss = 1-sigmoid(classLabels[x] * p[0, 0])    #计算损失\n",
    "            \n",
    "            w_0 = w_0 + alpha * loss * classLabels[x]\n",
    "            \n",
    "            for i in range(n):\n",
    "                if dataMatrix[x, i] != 0:\n",
    "                    w[i, 0] = w[i, 0] + alpha * loss * classLabels[x] * dataMatrix[x, i]\n",
    "                    for j in range(k):\n",
    "                        v[i, j] = v[i, j] + alpha * loss * classLabels[x] * (dataMatrix[x, i] * inter_1[0, j] - v[i, j] * dataMatrix[x, i] * dataMatrix[x, i])\n",
    "        print(\"第{}次迭代后的损失为{}\".format(it, loss))\n",
    "        \n",
    "    return w_0, w, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(dataMatrix, classLabels, w_0, w, v):\n",
    "    m, n = shape(dataMatrix)\n",
    "    allItem = 0\n",
    "    error = 0\n",
    "    result = []\n",
    "    for x in range(m):   #计算每一个样本的误差\n",
    "        allItem += 1\n",
    "        inter_1 = dataMatrix[x] * v\n",
    "        inter_2 = np.multiply(dataMatrix[x], dataMatrix[x]) * np.multiply(v, v)\n",
    "        interaction = sum(np.multiply(inter_1, inter_1) - inter_2) / 2.\n",
    "        p = w_0 + dataMatrix[x] * w + interaction  # 计算预测的输出\n",
    "        \n",
    "        pre = sigmoid(p[0, 0])\n",
    "        result.append(pre)\n",
    "        \n",
    "        if pre < 0.5 and classLabels[x] == 1.0:\n",
    "            error += 1\n",
    "        elif pre >= 0.5 and classLabels[x] == -1.0:\n",
    "            error += 1\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return float(error) / allItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练\n",
      "第0次迭代后的损失为0.3911898262308078\n",
      "第1次迭代后的损失为0.40130266249842506\n",
      "第2次迭代后的损失为0.42037798212389\n",
      "第3次迭代后的损失为0.43813110118777243\n",
      "第4次迭代后的损失为0.4534829893947645\n",
      "第5次迭代后的损失为0.46629410857294096\n",
      "第6次迭代后的损失为0.47672997630527836\n",
      "第7次迭代后的损失为0.485067441395417\n",
      "第8次迭代后的损失为0.49160565591446825\n",
      "第9次迭代后的损失为0.49662664083034713\n",
      "第10次迭代后的损失为0.50037954830209\n",
      "第11次迭代后的损失为0.5030767154627553\n",
      "第12次迭代后的损失为0.5048955334590437\n",
      "第13次迭代后的损失为0.505982834736846\n",
      "第14次迭代后的损失为0.5064599655083015\n",
      "第15次迭代后的损失为0.5064275945885104\n",
      "第16次迭代后的损失为0.5059698437046845\n",
      "第17次迭代后的损失为0.5051576301825677\n",
      "第18次迭代后的损失为0.5040512720462818\n",
      "第19次迭代后的损失为0.502702474234043\n",
      "第20次迭代后的损失为0.5011558308893636\n",
      "第21次迭代后的损失为0.4994499675624756\n",
      "第22次迭代后的损失为0.4976184244411661\n",
      "第23次迭代后的损失为0.49569035674170214\n",
      "第24次迭代后的损失为0.493691106018311\n",
      "第25次迭代后的损失为0.49164267840181786\n",
      "第26次迭代后的损失为0.4895641529350907\n",
      "第27次迭代后的损失为0.4874720346134047\n",
      "第28次迭代后的损失为0.48538056148653563\n",
      "第29次迭代后的损失为0.48330197223692417\n",
      "第30次迭代后的损失为0.48124673916032445\n",
      "第31次迭代后的损失为0.4792237707957535\n",
      "第32次迭代后的损失为0.4772405881408075\n",
      "第33次迭代后的损失为0.4753034781817541\n",
      "第34次迭代后的损失为0.4734176282304813\n",
      "第35次迭代后的损失为0.4715872442452562\n",
      "第36次迭代后的损失为0.4698156559234292\n",
      "第37次迭代后的损失为0.4681054109208086\n",
      "第38次迭代后的损失为0.46645836011000874\n",
      "第39次迭代后的损失为0.4648757353709878\n",
      "第40次迭代后的损失为0.4633582210346271\n",
      "第41次迭代后的损失为0.46190601978841683\n",
      "第42次迭代后的损失为0.4605189136068216\n",
      "第43次迭代后的损失为0.45919632008573463\n",
      "第44次迭代后的损失为0.4579373444338245\n",
      "第45次迭代后的损失为0.4567408272941744\n",
      "第46次迭代后的损失为0.4556053885273694\n",
      "第47次迭代后的损失为0.45452946707208985\n",
      "第48次迭代后的损失为0.4535113570025736\n",
      "第49次迭代后的损失为0.45254923991666574\n",
      "第50次迭代后的损失为0.45164121380776856\n",
      "第51次迭代后的损失为0.4507853185946584\n",
      "第52次迭代后的损失为0.44997955850190363\n",
      "第53次迭代后的损失为0.44922192149871776\n",
      "第54次迭代后的损失为0.4485103960145884\n",
      "第55次迭代后的损失为0.4478429851557493\n",
      "第56次迭代后的损失为0.4472177186475762\n",
      "第57次迭代后的损失为0.4466326627248953\n",
      "第58次迭代后的损失为0.44608592818553194\n",
      "第59次迭代后的损失为0.4455756768129483\n",
      "第60次迭代后的损失为0.4451001263622423\n",
      "第61次迭代后的损失为0.444657554290682\n",
      "第62次迭代后的损失为0.44424630039998636\n",
      "第63次迭代后的损失为0.44386476854323054\n",
      "第64次迭代后的损失为0.4435114275348102\n",
      "第65次迭代后的损失为0.44318481138797217\n",
      "第66次迭代后的损失为0.442883518990836\n",
      "第67次迭代后的损失为0.44260621331917505\n",
      "第68次迭代后的损失为0.4423516202723152\n",
      "第69次迭代后的损失为0.4421185272075715\n",
      "第70次迭代后的损失为0.44190578123859225\n",
      "第71次迭代后的损失为0.44171228735399004\n",
      "第72次迭代后的损失为0.44153700640442595\n",
      "第73次迭代后的损失为0.44137895299911156\n",
      "第74次迭代后的损失为0.4412371933462199\n",
      "第75次迭代后的损失为0.4411108430660682\n",
      "第76次迭代后的损失为0.4409990650009554\n",
      "第77次迭代后的损失为0.4409010670412429\n",
      "第78次迭代后的损失为0.440816099983523\n",
      "第79次迭代后的损失为0.44074345543350646\n",
      "第80次迭代后的损失为0.44068246376352915\n",
      "第81次迭代后的损失为0.44063249213220035\n",
      "第82次迭代后的损失为0.4405929425717764\n",
      "第83次迭代后的损失为0.4405632501471447\n",
      "第84次迭代后的损失为0.44054288118892215\n",
      "第85次迭代后的损失为0.44053133160202673\n",
      "第86次迭代后的损失为0.44052812525012086\n",
      "第87次迭代后的损失为0.44053281241554765\n",
      "第88次迭代后的损失为0.4405449683337854\n",
      "第89次迭代后的损失为0.44056419180092277\n",
      "第90次迭代后的损失为0.4405901038522878\n",
      "第91次迭代后的损失为0.44062234651008847\n",
      "第92次迭代后的损失为0.4406605815976553\n",
      "第93次迭代后的损失为0.44070448961780473\n",
      "第94次迭代后的损失为0.4407537686926609\n",
      "第95次迭代后的损失为0.44080813356229653\n",
      "第96次迭代后的损失为0.44086731463947193\n",
      "第97次迭代后的损失为0.4409310571178189\n",
      "第98次迭代后的损失为0.44099912013079856\n",
      "第99次迭代后的损失为0.44107127595886964\n",
      "第100次迭代后的损失为0.44114730928232637\n",
      "第101次迭代后的损失为0.4412270164773672\n",
      "第102次迭代后的损失为0.44131020495304096\n",
      "第103次迭代后的损失为0.4413966925267906\n",
      "第104次迭代后的损失为0.4414863068364464\n",
      "第105次迭代后的损失为0.4415788847865675\n",
      "第106次迭代后的损失为0.44167427202717857\n",
      "第107次迭代后的损失为0.4417723224630058\n",
      "第108次迭代后的损失为0.4418728977914367\n",
      "第109次迭代后的损失为0.44197586706750636\n",
      "第110次迭代后的损失为0.44208110629432007\n",
      "第111次迭代后的损失为0.4421884980373806\n",
      "第112次迭代后的损失为0.4422979310614198\n",
      "第113次迭代后的损失为0.442409299988364\n",
      "第114次迭代后的损失为0.4425225049751681\n",
      "第115次迭代后的损失为0.4426374514103445\n",
      "第116次迭代后的损失为0.442754049628034\n",
      "第117次迭代后的损失为0.44287221463858106\n",
      "第118次迭代后的损失为0.4429918658746036\n",
      "第119次迭代后的损失为0.4431129269516534\n",
      "第120次迭代后的损失为0.4432353254425444\n",
      "第121次迭代后的损失为0.44335899266457757\n",
      "第122次迭代后的损失为0.4434838634788407\n",
      "第123次迭代后的损失为0.44360987610089286\n",
      "第124次迭代后的损失为0.4437369719221481\n",
      "第125次迭代后的损失为0.4438650953412926\n",
      "第126次迭代后的损失为0.44399419360517733\n",
      "第127次迭代后的损失为0.44412421665858903\n",
      "第128次迭代后的损失为0.4442551170023976\n",
      "第129次迭代后的损失为0.4443868495595702\n",
      "第130次迭代后的损失为0.44451937154859356\n",
      "第131次迭代后的损失为0.44465264236387414\n",
      "第132次迭代后的损失为0.4447866234626966\n",
      "第133次迭代后的损失为0.4449212782583737\n",
      "第134次迭代后的损失为0.4450565720192091\n",
      "第135次迭代后的损失为0.44519247177295806\n",
      "第136次迭代后的损失为0.4453289462164406\n",
      "第137次迭代后的损失为0.44546596563004803\n",
      "第138次迭代后的损失为0.44560350179682084\n",
      "第139次迭代后的损失为0.4457415279258802\n",
      "第140次迭代后的损失为0.44588001857992376\n",
      "第141次迭代后的损失为0.4460189496065907\n",
      "第142次迭代后的损失为0.44615829807345575\n",
      "第143次迭代后的损失为0.44629804220645564\n",
      "第144次迭代后的损失为0.446438161331561\n",
      "第145次迭代后的损失为0.44657863581950474\n",
      "第146次迭代后的损失为0.4467194470333994\n",
      "第147次迭代后的损失为0.4468605772790897\n",
      "第148次迭代后的损失为0.447002009758076\n",
      "第149次迭代后的损失为0.44714372852289164\n",
      "第150次迭代后的损失为0.4472857184347655\n",
      "第151次迭代后的损失为0.4474279651234865\n",
      "第152次迭代后的损失为0.4475704549493109\n",
      "第153次迭代后的损失为0.44771317496682683\n",
      "第154次迭代后的损失为0.44785611289067606\n",
      "第155次迭代后的损失为0.44799925706299715\n",
      "第156次迭代后的损失为0.4481425964225466\n",
      "第157次迭代后的损失为0.4482861204753692\n",
      "第158次迭代后的损失为0.44842981926696124\n",
      "第159次迭代后的损失为0.44857368335582315\n",
      "第160次迭代后的损失为0.4487177037883656\n",
      "第161次迭代后的损失为0.44886187207504846\n",
      "第162次迭代后的损失为0.4490061801677373\n",
      "第163次迭代后的损失为0.4491506204381699\n",
      "第164次迭代后的损失为0.44929518565752224\n",
      "第165次迭代后的损失为0.44943986897696775\n",
      "第166次迭代后的损失为0.44958466390921403\n",
      "第167次迭代后的损失为0.4497295643109529\n",
      "第168次迭代后的损失为0.44987456436617457\n",
      "第169次迭代后的损失为0.4500196585703159\n",
      "第170次迭代后的损失为0.45016484171517646\n",
      "第171次迭代后的损失为0.4503101088745882\n",
      "第172次迭代后的损失为0.45045545539078213\n",
      "第173次迭代后的损失为0.45060087686142947\n",
      "第174次迭代后的损失为0.4507463691273116\n",
      "第175次迭代后的损失为0.4508919282605973\n",
      "第176次迭代后的损失为0.45103755055368977\n",
      "第177次迭代后的损失为0.4511832325086237\n",
      "第178次迭代后的损失为0.45132897082696666\n",
      "第179次迭代后的损失为0.4514747624002252\n",
      "第180次迭代后的损失为0.45162060430070583\n",
      "第181次迭代后的损失为0.4517664937728285\n",
      "第182次迭代后的损失为0.4519124282248572\n",
      "第183次迭代后的损失为0.4520584052210267\n",
      "第184次迭代后的损失为0.45220442247405956\n",
      "第185次迭代后的损失为0.45235047783803517\n",
      "第186次迭代后的损失为0.45249656930161153\n",
      "第187次迭代后的损失为0.4526426949815654\n",
      "第188次迭代后的损失为0.45278885311665074\n",
      "第189次迭代后的损失为0.45293504206175317\n",
      "第190次迭代后的损失为0.4530812602823159\n",
      "第191次迭代后的损失为0.4532275063490493\n",
      "第192次迭代后的损失为0.45337377893287734\n",
      "第193次迭代后的损失为0.4535200768001446\n",
      "第194次迭代后的损失为0.4536663988080356\n",
      "第195次迭代后的损失为0.4538127439002301\n",
      "第196次迭代后的损失为0.453959111102753\n",
      "第197次迭代后的损失为0.45410549952003343\n",
      "第198次迭代后的损失为0.4542519083311486\n",
      "第199次迭代后的损失为0.4543983367862461\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f2f85f40d851>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mw_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGD_FM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataTrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"训练准确性为：%f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mgetAccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataTrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdate_endTrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mat' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train = pd.read_csv(trainData)\n",
    "    test = pd.read_csv(testData)\n",
    "    dataTrain, labelTrain = preprocessData(train)\n",
    "    dataTest, labelTest = preprocessData(test)\n",
    "    date_startTrain = datetime.now()\n",
    "    \n",
    "    print    (\"开始训练\")\n",
    "    \n",
    "    w_0, w, v = SGD_FM(np.mat(dataTrain), labelTrain, 20, 200)\n",
    "    print(\"训练准确性为：%f\" % (1 - getAccuracy(mat(dataTrain), labelTrain, w_0, w, v)))\n",
    "    \n",
    "    date_endTrain = datetime.now()\n",
    "    print(\"训练用时为：%s\" % (date_endTrain - date_startTrain))\n",
    "    \n",
    "    print(\"开始测试\")\n",
    "    print(\"测试准确性为：%f\" % (1 - getAccuracy(np.mat(dataTest), labelTest, w_0, w, v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
